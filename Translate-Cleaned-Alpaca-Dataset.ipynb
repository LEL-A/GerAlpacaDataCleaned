{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe3fba-2f98-4639-b9d6-23b06a42c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import requests\n",
    "\n",
    "from transformers import FSMTForConditionalGeneration, FSMTTokenizer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fad5e0-aace-4e68-9204-69a7d9e94ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974be8a6-ef79-4d9f-9624-4666b7d00822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download cleaned Alpaca Dataset from: https://github.com/gururise/AlpacaDataCleaned\n",
    "# Use specific commit (current latest main) for reproducability)\n",
    "r = requests.get(\"https://raw.githubusercontent.com/gururise/AlpacaDataCleaned/2ee9f5ca1d4dc2df3777a765bab88ad061e83378/alpaca_data_cleaned.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c068446-f22e-411a-bcf7-d11090ee8576",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not r:\n",
    "    print(\"Error downloading dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cc0ddc-c0e0-45a0-8947-f375ad2ed2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af90a6c-8532-4801-9635-71d488ecd923",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"facebook/wmt19-en-de\"\n",
    "tokenizer = FSMTTokenizer.from_pretrained(model_name)\n",
    "model = FSMTForConditionalGeneration.from_pretrained(model_name)\n",
    "model.to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545178b-18e4-48dd-8901-53ebb7c2229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_instructions = [ example[\"instruction\"].replace(\"\\n\", \"<br>\") for example in data]\n",
    "source_inputs = [ example[\"input\"].replace(\"\\n\", \"<br>\") for example in data]\n",
    "source_outputs = [ example[\"output\"].replace(\"\\n\", \"<br>\") for example in data]\n",
    "\n",
    "def generate_batches(input_list: List[str], batch_size: int):\n",
    "    for i in range(0, len(input_list), batch_size):\n",
    "        yield input_list[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4091e-9380-4457-82b5-f3754f32f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_instruction_batches = generate_batches(source_instructions, 128)\n",
    "source_input_batches = generate_batches(source_inputs, 128)\n",
    "source_output_batches = generate_batches(source_outputs, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6b618-4afe-4b9a-bd01-ad743dda37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(batch: List[str]):\n",
    "    tokenized_batch = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "    generate_kwargs = {\"num_beams\": 1, \"do_sample\": True, \"num_return_sequences\": 1, \"max_length\": 512}\n",
    "    translated_texts = model.generate(tokenized_batch[\"input_ids\"].to(device=\"cuda:0\"),\n",
    "                                      attention_mask=tokenized_batch[\"attention_mask\"].to(device=\"cuda:0\"),\n",
    "                                      top_p=0.8, **generate_kwargs)\n",
    "    \n",
    "    return [tokenizer.decode(t, skip_special_tokens=True).replace(\"< br > \", \"\\n\") for t in translated_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab99bab-3064-48f3-9a32-b0610c131c51",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "translated_instructions = []\n",
    "translated_inputs = []\n",
    "translated_outputs = []\n",
    "\n",
    "for index, batch in enumerate(source_instruction_batches):\n",
    "    print(f\"Translating Instruction Batch {index+1}\")\n",
    "    translated_batch = translate(batch)\n",
    "    translated_instructions.extend(translated_batch)\n",
    "\n",
    "for index, batch in enumerate(source_input_batches):\n",
    "    print(f\"Translating Input Batch {index+1}\")\n",
    "    translated_batch = translate(batch)\n",
    "    translated_inputs.extend(translated_batch)\n",
    "   \n",
    "for index, batch in enumerate(source_output_batches):\n",
    "    print(f\"Translating Output Batch {index+1}\")\n",
    "    translated_batch = translate(batch)\n",
    "    translated_outputs.extend(translated_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8ea56-887e-4072-857a-61bf7dd8926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_data = []\n",
    "\n",
    "for source_input, translated_input, translated_instruction, translated_output in zip(source_inputs,\n",
    "                                                                                     translated_inputs,\n",
    "                                                                                     translated_instructions,\n",
    "                                                                                     translated_outputs):\n",
    "    current_example = {\n",
    "        \"instruction\": translated_instruction,\n",
    "        \"input\": translated_input if source_input else \"\",\n",
    "        \"output\": translated_output\n",
    "    }\n",
    "    translated_data.append(current_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736d7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"translated_german_alpaca.json\", \"wt\") as f_p:\n",
    "    json.dump(translated_data, f_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
